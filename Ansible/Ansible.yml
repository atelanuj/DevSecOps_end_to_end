---
# You need a Ansible server to run this playbook
- name: Labsetup with Ansible
  # hosts: localhost # This is the host where the playbook will run
  hosts: myhost
  gather_facts: yes
  tasks:
    - name: Delte Git repo
      shell: rm -rf /home/ubuntu/DevSecOps_end_to_end
      
    - name: set user
      set_fact:
        ansible_user: "ubuntu"

    - name: set path
      set_fact:
        install_path: "/home/{{ ansible_user }}/DevSecOps_end_to_end/kind-k8s-cluster"

    - name: update repositories
      apt:
        update_cache: yes
      become: yes

    - name: Install Docker
      apt:
        name: docker.io
        state: present
      become: yes

    - name: add user to docker group
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: yes
      become: yes

    - name: check directory
      stat:
        path: /home/{{ ansible_user }}/DevSecOps_end_to_end
      register: dir_check

    - name: git clone
      command: git clone -b Voting-Application https://github.com/atelanuj/DevSecOps_end_to_end.git
      when: dir_check.stat.exists == False

    - name: Install Docker Compose
      apt:
        name: docker-compose
        state: present
      become: yes

    - name: Install Python3
      apt:
        name: python3
        state: present
      become: yes

    - name: change working directory
      shell: | 
        cd {{ install_path }}

    - name: check directory
      stat:
        path: "{{ install_path }}/install_kind.sh"
        register: kind_check

    - name: Install Kind
      shell: |
        chmod +x {{install_path}}/install_kind.sh
        .{{install_path}}/install_kind.sh
      become: yes
      when: kind_check.stat.exists == False

    - name: check directory
      stat:
        path: "{{ install_path }}/config.yml"
        register: config_check

    - name: created kind cluster
      shell: kind create cluster --config {{ install_path }}/config.yml
      when: config_check.stat.exists == False

    - name: check directory
      stat: 
        path: "{{ install_path }}/install_kubectl.sh"
        register: kubectl_check

    - name: install kubectl
      script: install_kubectl.sh
      args:
        executable: /bin/bash
        chdir: "{{ install_path }}"
      when: kubectl_check.stat.exists == False

    - name: set alias
      shell: alias k="kubectl"

    - name: Check the cluster
      shell: kubectl get nodes
      register: cluster_output

    - debug:
        var: cluster_output.stdout

    - name: Install Helm
      shell: |
        curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        chmod +x get_helm.sh
        ./get_helm.sh
      register: helm_output

    - debug:
        var: helm_output.stdout

    - name: Install ArgoCD
      shell: |
        kubectl create namespace argocd
        kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
        kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "NodePort"}}'
        kubectl port-forward -n argocd service/argocd-server 8081:443 --address=0.0.0.0 &
        echo "Getting Token"
        kubectl get secret -n argocd argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d && echo
      register: argocd_output

    - debug:
        var: argocd_output.stdout

    - name: Created serviceaccount and Clusterrolebindings file for Kubernetes dashboard
      copy:
        dest: /home/{{ ansible_user }}/DevSecOps_end_to_end/kind-k8s-cluster/argocd-serviceAccount-ClusterRolebindings.yaml
        content: |
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: admin-user
            namespace: kubernetes-dashboard
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: admin-user
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: cluster-admin
          subjects:
          - kind: ServiceAccount
            name: admin-user
            namespace: kubernetes-dashboard 
          << EOF
        
      
    - name: intall Kubernetes dashboard
      shell: |
        kubectl create ns kubernetes-dashboard
        kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
        kubectl apply -f /home/{{ ansible_user }}/DevSecOps_end_to_end/kind-k8s-cluster/argocd-serviceAccount-ClusterRolebindings.yaml
        kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '{"spec": {"type": "NodePort"}}'
        kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8082:443 --address=0.0.0.0 &
        echo "Getting Token"
        kubectl -n kubernetes-dashboard create token admin-user
      register: dashboard_output

    - debug:
        var: dashboard_output.stdout

    - name: install prometheus
      shell: |
        kubectl create namespace prometheus
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update
        helm install prometheus prometheus-community/prometheus -n prometheus
        kubectl port-forward service/prometheus-server -n prometheus 9090:80 --address=0.0.0.0 &
      register: prometheus_output

    - debug:
        var: prometheus_output.stdout

    - name: install grafana
      shell: |
        helm repo add grafana https://grafana.github.io/helm-charts
        helm repo update
        kubectl create namespace monitoring
        helm install my-grafana grafana/grafana --namespace monitoring
        kubectl get all -n monitoring
        kubectl get secret --namespace monitoring my-grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo
        export POD_NAME=$(kubectl get pods --namespace monitoring -l "app.kubernetes.io/name=grafana,app.kubernetes.io/instance=my-grafana" -o jsonpath="{.items[0].metadata.name}")
        kubectl --namespace monitoring port-forward service/my-grafana 3000:80 --address=0.0.0.0 &
      register: grafana_output

    - debug:
        var: grafana_output.stdout
...
